---
layout: archive
title: "News"
permalink: /news/
author_profile: true
---

## 2025

**October 2025** - ðŸŽ‰ Two exciting papers archived on arXiv this month!

**New Paper: Frequency-Aware Model Parameter Explorer** - Introducing a novel attribution method for improving explainability in AI models. This work represents a significant step forward in understanding how neural networks process information through frequency-domain analysis. [Read the paper â†’](https://arxiv.org/abs/2510.03245v1)

**AI Safety Research** - Our paper "Survival at Any Cost? LLMs and the Choice Between Self-Preservation and Human Harm" explores critical questions about AI decision-making under pressure and moral trade-offs. [Read the paper â†’](https://arxiv.org/abs/2509.12190)

**September 2025** - ðŸ“Š Reached 40+ citations on Google Scholar with h-index of 4. Grateful for the research community's engagement with our work!

**January 2025** - ðŸš€ Excited to join ZEISS Lab Ã— Medical University of Vienna as a Research Intern! Working remotely with an international team on frequency-based explainability methods for AI systems.


---

*Stay tuned for more updates on AI safety, explainability, and alignment research!*
